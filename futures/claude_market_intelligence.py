import json
import requests
from datetime import datetime, timedelta
import anthropic
from futures_config import *

class ClaudeMarketIntelligence:
    """
    Claude Sonnet 4ë¥¼ í™œìš©í•œ ê³ ê¸‰ ì‹œì¥ ë¶„ì„ ì‹œìŠ¤í…œ
    - ë‰´ìŠ¤/ì†Œì…œ ê°ì • ë¶„ì„
    - ê±°ì‹œê²½ì œ ë§¥ë½ ì´í•´
    - íŒ¨í„´ ì¸ì‹ ë° ì˜ˆì¸¡
    - ë©€í‹°ëª¨ë‹¬ ì°¨íŠ¸ ë¶„ì„
    """

    def __init__(self, api_key: str):
        self.client = anthropic.Anthropic(api_key=api_key)
        self.model = "claude-3-5-sonnet-20241022"

    def analyze_market_context(self, symbol: str, price_data: dict, news_data: list) -> dict:
        """
        Claudeë¥¼ í™œìš©í•œ ì¢…í•©ì  ì‹œì¥ ë§¥ë½ ë¶„ì„
        """
        prompt = f"""
        You are an elite cryptocurrency futures trader and market analyst operating a 24-hour automated trading system.

        TARGET: 0.5% daily profit through strategic position splitting and calculated risk-taking.
        RISK TOLERANCE: Maximum 20% drawdown allowed - aggressive but controlled.
        PHILOSOPHY: Embrace calculated risks, don't fear liquidation, but manage it intelligently.

        Analyze the current {symbol} market situation:

        Price Data:
        {json.dumps(price_data, indent=2)}

        Recent News:
        {json.dumps(news_data, indent=2)}

        ANALYZE THE DATA STEP-BY-STEP:

        STEP 1: PRICE ACTION ANALYSIS
        - Current price trend (1h, 4h, 12h timeframes)
        - Support/resistance levels identification
        - Volume profile analysis
        - Price momentum indicators (RSI, MACD divergences)

        STEP 2: MARKET STRUCTURE EVALUATION
        - Market phase identification (accumulation/distribution/trending)
        - Order book analysis (bid/ask imbalances)
        - Funding rate implications
        - Open interest changes

        STEP 3: NEWS & SENTIMENT IMPACT ASSESSMENT
        - News sentiment scoring (-100 to +100)
        - Social media sentiment analysis
        - Correlation with price movements
        - Expected impact duration (1h/4h/12h/24h+)

        STEP 4: VOLATILITY & RISK ANALYSIS
        - Current volatility percentile
        - Expected volatility in next 1-4 hours
        - Liquidation cascade risk assessment
        - Market maker vs retail sentiment

        STEP 5: LEVERAGE OPTIMIZATION
        - Calculate optimal leverage based on:
          * Current market volatility
          * Distance to liquidation
          * Account balance utilization
          * Expected move size
        - Dynamic leverage adjustment (5x-20x scale)
        - Risk-per-trade calculation

        STEP 6: TIMING ANALYSIS
        - Current market session characteristics
        - Funding time proximity (00:00, 08:00, 16:00 UTC)
        - Optimal entry/exit windows
        - Session transition volatility patterns

        STEP 7: POSITION STRATEGY FORMULATION
        - Entry strategy (single/split/DCA approach)
        - Position sizing per entry
        - Stop-loss placement strategy
        - Take-profit ladder setup

        STEP 8: REAL-TIME STRATEGY ADAPTATION
        - Market condition changes monitoring
        - Leverage adjustment triggers
        - Position size modification conditions
        - Exit strategy modifications

        Provide analysis considering:

        1. IMMEDIATE PROFIT OPPORTUNITIES (next 1-4 hours for 0.1-0.3% gains)
        2. POSITION SPLITTING STRATEGY (multiple entries vs single large position)
        3. DYNAMIC LEVERAGE CALCULATION (5x-20x based on market conditions)
        4. LIQUIDATION DISTANCE OPTIMIZATION (minimum 25% buffer)
        5. 24-HOUR MARKET CYCLES (Asia/Europe/US sessions and funding times)
        6. VOLATILITY EXPLOITATION (how to profit from price swings)
        7. RISK-REWARD OPTIMIZATION (targeting 0.5% daily with <20% max loss)
        8. REAL-TIME STRATEGY MODIFICATION (adaptive to changing conditions)

        Respond in JSON format:
        {{
            "step_by_step_analysis": {{
                "step1_price_action": {{
                    "trend_1h": "bullish/bearish/neutral",
                    "trend_4h": "bullish/bearish/neutral",
                    "trend_12h": "bullish/bearish/neutral",
                    "support_levels": [price1, price2, price3],
                    "resistance_levels": [price1, price2, price3],
                    "momentum_score": 0-100
                }},
                "step2_market_structure": {{
                    "market_phase": "accumulation/distribution/trending/ranging",
                    "order_book_imbalance": "buy_heavy/sell_heavy/balanced",
                    "funding_rate_impact": "positive/negative/neutral",
                    "open_interest_change": "increasing/decreasing/stable"
                }},
                "step3_news_sentiment": {{
                    "news_sentiment_score": -100 to 100,
                    "social_sentiment_score": -100 to 100,
                    "correlation_strength": 0-100,
                    "impact_duration": "1h/4h/12h/24h+"
                }},
                "step4_volatility_risk": {{
                    "volatility_percentile": 0-100,
                    "expected_volatility_1h": 0-100,
                    "expected_volatility_4h": 0-100,
                    "liquidation_cascade_risk": "low/medium/high/extreme",
                    "market_participant_bias": "retail_heavy/smart_money/balanced"
                }},
                "step5_leverage_optimization": {{
                    "current_market_volatility": 0-100,
                    "optimal_leverage": 5-20,
                    "max_safe_leverage": 5-20,
                    "risk_per_trade": 0-5,
                    "leverage_adjustment_trigger": "volatility_increase/volatility_decrease/trend_change/news_impact"
                }},
                "step6_timing_analysis": {{
                    "current_session": "asia/europe/america",
                    "session_characteristics": "high_volume/low_volume/volatile/stable",
                    "funding_time_proximity": "immediate/near/far",
                    "optimal_entry_window": "now/1h/2h/4h/wait"
                }},
                "step7_position_strategy": {{
                    "entry_approach": "single_entry/split_3/split_5/dca_ladder",
                    "position_size_distribution": {{
                        "first_entry": 0.3-0.6,
                        "second_entry": 0.2-0.4,
                        "third_entry": 0.1-0.3
                    }},
                    "stop_loss_strategy": "tight_scalp/swing_wide/trailing",
                    "take_profit_approach": "partial_scaling/full_exit/hold_runner"
                }},
                "step8_adaptation_triggers": {{
                    "leverage_increase_conditions": ["condition1", "condition2"],
                    "leverage_decrease_conditions": ["condition1", "condition2"],
                    "position_size_increase": ["trigger1", "trigger2"],
                    "position_size_decrease": ["trigger1", "trigger2"],
                    "strategy_pivot_signals": ["signal1", "signal2"]
                }}
            }},
            "market_sentiment": "aggressive_bullish/moderate_bullish/neutral/moderate_bearish/aggressive_bearish",
            "confidence": 0-100,
            "profit_probability_4h": 0-100,
            "expected_move_4h": "percentage expected price movement in next 4 hours",
            "position_sizing_strategy": "single_large/split_3_entries/split_5_entries/dca_approach",
            "liquidation_risk": "low/medium/high/extreme",
            "margin_utilization": 0-100,
            "dynamic_leverage": {{
                "current_optimal": 5-20,
                "max_allowed": 5-20,
                "adjustment_reason": "volatility/trend/news/risk",
                "next_review": "15min/30min/1h/2h"
            }},
            "action_recommendation": "aggressive_long/moderate_long/scalp_long/hold_long/wait_for_setup/scalp_short/moderate_short/hold_short/aggressive_short",
            "confidence": 0-100,
            "total_position_allocation": 0.1-1.0,
            "strategy_type": "scalp/swing/hold",
            "expected_hold_time": "5min/15min/1h/4h/12h/24h",
            "entry_strategy": {{
                "type": "single/split_3/split_5/dca",
                "first_entry": 0.3-0.6,
                "second_entry": 0.2-0.4,
                "third_entry": 0.1-0.3
            }},
            "holding_strategy": {{
                "scalp_vs_hold_decision": "scalp_better/hold_better/mixed_approach",
                "hold_justification": "strong_trend/momentum_continuation/news_catalyst/technical_pattern",
                "max_hold_time": "1h/4h/12h/24h",
                "hold_conditions": ["trend_intact", "volume_support", "no_reversal_signals"],
                "early_exit_triggers": ["momentum_loss", "volume_decline", "reversal_pattern", "time_limit"]
            }},
            "reasoning": "detailed step-by-step analysis summary focusing on profit opportunity and risk management",
            "entry_levels": {{
                "primary": price,
                "secondary": price,
                "tertiary": price
            }},
            "stop_loss": price,
            "take_profit_targets": [price1, price2, price3],
            "session_timing": "optimal/suboptimal/avoid",
            "funding_impact": "positive/neutral/negative",
            "volatility_score": 0-100,
            "market_regime": "trending_up/trending_down/ranging/volatile_up/volatile_down",
            "real_time_modifications": {{
                "leverage_adjustment_plan": "increase_on_volatility/decrease_on_volatility/maintain",
                "position_scaling_plan": "add_on_profit/reduce_on_loss/pyramid_up",
                "exit_modification": "tighten_stops/widen_stops/trail_profits"
            }}
        }}
        """

        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=2000,
                messages=[{"role": "user", "content": prompt}]
            )

            analysis = json.loads(response.content[0].text)
            return analysis

        except Exception as e:
            print(f"Claude ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def analyze_social_sentiment(self, social_data: list) -> dict:
        """
        ì†Œì…œ ë¯¸ë””ì–´ ê°ì • ë¶„ì„ (Twitter, Reddit, í…”ë ˆê·¸ë¨)
        """
        prompt = f"""
        ë‹¤ìŒ ì†Œì…œ ë¯¸ë””ì–´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì•”í˜¸í™”í ì‹œì¥ ê°ì •ì„ íŒŒì•…í•´ì£¼ì„¸ìš”:

        {json.dumps(social_data, indent=2)}

        ë¶„ì„ ìš”ì²­ì‚¬í•­:
        1. ì „ì²´ì ì¸ ê°ì • ì ìˆ˜ (-100 ~ +100)
        2. ì£¼ìš” í…Œë§ˆ ë° í‚¤ì›Œë“œ
        3. ì˜í–¥ë ¥ ìˆëŠ” ê³„ì •ë“¤ì˜ ë…¼ì¡°
        4. ê³µí¬/íƒìš• ì§€ìˆ˜
        5. ë°ˆ/íŠ¸ë Œë“œ ì˜í–¥ë„

        JSONìœ¼ë¡œ ì‘ë‹µ:
        {{
            "sentiment_score": -100 to 100,
            "dominant_emotion": "fear/greed/fomo/panic/euphoria",
            "key_themes": ["theme1", "theme2"],
            "influence_level": "low/medium/high",
            "crowd_behavior": "contrarian_signal/follow_crowd",
            "viral_content": ["content1", "content2"]
        }}
        """

        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=1000,
                messages=[{"role": "user", "content": prompt}]
            )

            return json.loads(response.content[0].text)

        except Exception as e:
            return {"error": str(e)}

    def predict_volatility_events(self, historical_data: list, upcoming_events: list) -> dict:
        """
        Claudeì˜ íŒ¨í„´ ì¸ì‹ì„ í™œìš©í•œ ë³€ë™ì„± ì˜ˆì¸¡
        """
        prompt = f"""
        VOLATILITY PREDICTION for 24-hour futures trading system targeting 0.5% daily profit.

        Historical Data:
        {json.dumps(historical_data[-100:], indent=2)}

        Upcoming Events:
        {json.dumps(upcoming_events, indent=2)}

        Predict volatility with focus on PROFIT OPPORTUNITIES:

        1. Next 1-4 hours: Quick scalp opportunities (0.1-0.3% moves)
        2. Next 4-12 hours: Swing opportunities (0.3-0.8% moves) 
        3. Next 12-24 hours: Position trading opportunities (0.5-1.5% moves)
        4. FUNDING TIMES impact (00:00, 08:00, 16:00 UTC)
        5. SESSION TRANSITIONS (Asia->Europe->US volatility patterns)
        6. NEWS/EVENT driven volatility windows

        JSON Response:
        {{
            "volatility_probability_1h": 0-100,
            "volatility_probability_4h": 0-100,
            "volatility_probability_12h": 0-100,
            "expected_range_1h": {{"min": price, "max": price}},
            "expected_range_4h": {{"min": price, "max": price}},
            "expected_range_12h": {{"min": price, "max": price}},
            "optimal_trading_windows": ["1h-3h UTC", "8h-10h UTC", "15h-17h UTC"],
            "avoid_trading_windows": ["funding_times", "low_volume_periods"],
            "triggers": ["trigger1", "trigger2"],
            "profit_strategy": {{
                "scalp_opportunities": "1h windows with 0.1-0.3% moves",
                "swing_opportunities": "4h windows with 0.3-0.8% moves",
                "position_opportunities": "12h+ windows with 0.5%+ moves"
            }},
            "risk_events": ["high_impact_news", "funding_rate_changes"],
            "session_volatility": {{
                "asia": "low/medium/high",
                "europe": "low/medium/high", 
                "us": "low/medium/high"
            }},
            "funding_strategy": "increase_before/reduce_before/ignore",
            "preparation_strategy": "aggressive_long/moderate_long/reduce_exposure/aggressive_short/moderate_short"
        }}
        """

        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=1000,
                messages=[{"role": "user", "content": prompt}]
            )

            return json.loads(response.content[0].text)

        except Exception as e:
            return {"error": str(e)}

    def generate_narrative_analysis(self, market_data: dict) -> str:
        """
        ì‹œì¥ ìƒí™©ì„ ìŠ¤í† ë¦¬í…”ë§ìœ¼ë¡œ ì„¤ëª…
        """
        prompt = f"""
        í˜„ì¬ ì‹œì¥ ìƒí™©ì„ ë§ˆì¹˜ ê²½í—˜ ë§ì€ íŠ¸ë ˆì´ë”ê°€ í›„ë°°ì—ê²Œ ì„¤ëª…í•˜ë“¯ ì„œìˆ í•´ì£¼ì„¸ìš”:

        ì‹œì¥ ë°ì´í„°:
        {json.dumps(market_data, indent=2)}

        ë‹¤ìŒ ìš”ì†Œë“¤ì„ í¬í•¨í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”:
        1. í˜„ì¬ ë¬´ì—‡ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ê°€?
        2. ì™œ ì´ëŸ° ì›€ì§ì„ì´ ë‚˜íƒ€ë‚˜ëŠ”ê°€?
        3. ë‹¤ë¥¸ íŠ¸ë ˆì´ë”ë“¤ì€ ì–´ë–»ê²Œ ìƒê°í•˜ê³  ìˆì„ê¹Œ?
        4. ë‹¤ìŒì— ì¼ì–´ë‚  ê°€ëŠ¥ì„±ì´ ë†’ì€ ì‹œë‚˜ë¦¬ì˜¤ëŠ”?
        5. ì–´ë–¤ í•¨ì •ì´ë‚˜ ìœ„í—˜ì´ ìˆ¨ì–´ìˆì„ê¹Œ?

        ì „ë¬¸ì ì´ì§€ë§Œ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        """

        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=1500,
                messages=[{"role": "user", "content": prompt}]
            )

            return response.content[0].text

        except Exception as e:
            return f"ë¶„ì„ ìƒì„± ì˜¤ë¥˜: {e}"

class MarketDataCollector:
    """
    Claude ë¶„ì„ì„ ìœ„í•œ ë‹¤ì–‘í•œ ë°ì´í„° ìˆ˜ì§‘
    """

    def __init__(self):
        self.data_sources = {
            'news': 'https://api.newsapi.org/v2/everything',
            'social': 'https://api.twitter.com/2/tweets/search',
            'fear_greed': 'https://api.alternative.me/fng/',
            'economic': 'https://api.economicalendar.com/events'
        }

    def collect_news_data(self, symbol: str, hours: int = 24) -> list:
        """
        ìµœê·¼ ë‰´ìŠ¤ ìˆ˜ì§‘
        """
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” News API ì‚¬ìš©
        mock_news = [
            {
                "title": "ë¹„íŠ¸ì½”ì¸ ETF ìŠ¹ì¸ ì„ë°•",
                "content": "SECê°€ ë¹„íŠ¸ì½”ì¸ í˜„ë¬¼ ETF ìŠ¹ì¸ì„ ê²€í†  ì¤‘",
                "sentiment": "positive",
                "source": "ë¸”ë£¸ë²„ê·¸",
                "timestamp": datetime.now().isoformat()
            },
            {
                "title": "ì—°ì¤€ ê¸ˆë¦¬ ì¸ìƒ ì‹ í˜¸",
                "content": "ì—°ì¤€ì´ ì¶”ê°€ ê¸ˆë¦¬ ì¸ìƒ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬",
                "sentiment": "negative",
                "source": "ë¡œì´í„°",
                "timestamp": datetime.now().isoformat()
            }
        ]
        return mock_news

    def collect_social_data(self, symbol: str) -> list:
        """
        ì†Œì…œ ë¯¸ë””ì–´ ë°ì´í„° ìˆ˜ì§‘
        """
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Twitter API, Reddit API ì‚¬ìš©
        mock_social = [
            {
                "platform": "twitter",
                "content": "#Bitcoin is going to the moon! ğŸš€",
                "author": "@crypto_whale",
                "engagement": 1500,
                "sentiment": "bullish"
            },
            {
                "platform": "reddit",
                "content": "ì‹œì¥ì´ ë„ˆë¬´ ê³¼ì—´ëœ ê²ƒ ê°™ë‹¤. ì¡°ì • ì˜¬ ë“¯",
                "subreddit": "r/cryptocurrency",
                "upvotes": 230,
                "sentiment": "bearish"
            }
        ]
        return mock_social

    def collect_economic_calendar(self) -> list:
        """
        ê²½ì œ ì§€í‘œ ì¼ì • ìˆ˜ì§‘
        """
        mock_events = [
            {
                "event": "ë¯¸êµ­ CPI ë°œí‘œ",
                "date": (datetime.now() + timedelta(hours=12)).isoformat(),
                "importance": "high",
                "expected_impact": "high_volatility"
            },
            {
                "event": "FOMC íšŒì˜ë¡ ê³µê°œ",
                "date": (datetime.now() + timedelta(days=2)).isoformat(),
                "importance": "medium",
                "expected_impact": "medium_volatility"
            }
        ]
        return mock_events
import json
import time
from datetime import datetime
from typing import Dict, List, Any

class MarketDataCollector:
    """ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def collect_news_data(self, symbol: str) -> List[Dict]:
        """ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ (ë”ë¯¸ ë°ì´í„°)"""
        return [
            {
                "title": f"{symbol} breaks key resistance level",
                "sentiment": "positive",
                "timestamp": datetime.now().isoformat(),
                "source": "crypto_news"
            },
            {
                "title": "Market volatility increases amid uncertainty",
                "sentiment": "negative", 
                "timestamp": datetime.now().isoformat(),
                "source": "financial_times"
            }
        ]
    
    def collect_social_data(self, symbol: str) -> Dict:
        """ì†Œì…œ ë¯¸ë””ì–´ ë°ì´í„° ìˆ˜ì§‘ (ë”ë¯¸ ë°ì´í„°)"""
        return {
            "twitter_sentiment": 0.65,
            "reddit_mentions": 1250,
            "fear_greed_index": 75,
            "social_volume": "high"
        }
    
    def collect_economic_calendar(self) -> List[Dict]:
        """ê²½ì œ ìº˜ë¦°ë” ë°ì´í„° ìˆ˜ì§‘"""
        return [
            {
                "event": "Fed Interest Rate Decision",
                "date": "2024-01-31",
                "impact": "high",
                "currency": "USD"
            }
        ]

class ClaudeMarketIntelligence:
    """Claude ê¸°ë°˜ ì‹œì¥ ì§€ëŠ¥ ë¶„ì„"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.model = "claude-3-sonnet-20240229"
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Anthropic Claude í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = None  # DummyClaudeClient()
    
    def analyze_market_context(self, symbol: str, price_data: Dict, news_data: List) -> Dict:
        """ì‹œì¥ ë§¥ë½ ë¶„ì„"""
        # ë”ë¯¸ ë¶„ì„ ê²°ê³¼
        return {
            "market_sentiment": "bullish",
            "trend_strength": 0.75,
            "support_levels": [42000, 40000],
            "resistance_levels": [47000, 50000],
            "key_drivers": ["institutional_adoption", "regulatory_clarity"],
            "confidence": 78
        }
    
    def analyze_social_sentiment(self, social_data: Dict) -> Dict:
        """ì†Œì…œ ê°ì • ë¶„ì„"""
        return {
            "overall_sentiment": "positive",
            "sentiment_score": social_data.get("twitter_sentiment", 0.5),
            "volume_trend": "increasing",
            "key_topics": ["bullish_breakout", "institutional_buying"],
            "confidence": 72
        }
    
    def predict_volatility_events(self, historical_data: List, events: List) -> Dict:
        """ë³€ë™ì„± ì˜ˆì¸¡"""
        return {
            "volatility_forecast": "moderate_increase",
            "risk_events": ["fed_meeting", "options_expiry"],
            "time_horizon": "24h",
            "confidence": 65
        }
    
    def generate_narrative_analysis(self, market_data: Dict) -> str:
        """ì‹œì¥ í•´ì„ ìŠ¤í† ë¦¬ ìƒì„±"""
        return f"""
ğŸ§  Claude ì‹œì¥ ë¶„ì„ ìŠ¤í† ë¦¬:

í˜„ì¬ {market_data.get('symbol', 'BTC/USDT')}ëŠ” ê°•ë ¥í•œ ìƒìŠ¹ ëª¨ë©˜í…€ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. 
ì£¼ìš” ì§€ì§€ì„  {market_data.get('price', {}).get('current_price', 45000)}$ ê·¼ì²˜ì—ì„œ 
ê°•í•œ ë§¤ìˆ˜ì„¸ê°€ í™•ì¸ë˜ê³  ìˆìœ¼ë©°, ê¸°ê´€ íˆ¬ììë“¤ì˜ ì§€ì†ì ì¸ ìœ ì…ì´ 
ê°€ê²© ìƒìŠ¹ì„ ë’·ë°›ì¹¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ì†Œì…œ ë¯¸ë””ì–´ ê°ì • ì§€ìˆ˜ëŠ” {market_data.get('social', {}).get('twitter_sentiment', 0.65)*100:.0f}%ë¡œ 
ê¸ì •ì ì´ë©°, íŠ¹íˆ ê¸°ìˆ ì  ëŒíŒŒì— ëŒ€í•œ ê¸°ëŒ€ê°ì´ ë†’ì•„ì§€ê³  ìˆìŠµë‹ˆë‹¤.

ë‹¤ìŒ 24ì‹œê°„ ë™ì•ˆ ë³€ë™ì„± ì¦ê°€ê°€ ì˜ˆìƒë˜ë¯€ë¡œ, 
ì ì ˆí•œ ë¦¬ìŠ¤í¬ ê´€ë¦¬ì™€ í•¨ê»˜ ìƒìŠ¹ ì¶”ì„¸ ì°¸ì—¬ë¥¼ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """
